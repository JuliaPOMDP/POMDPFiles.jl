const REGEX_FLOATING_POINT = r"[-+]?[0-9]*\.?[0-9]+"
"""
    Read a `.alpha` file as generated by pomdp-solve.
    Works the same was as `read_pomdp` in `POMDPXFile.jl`.

    The `.alpha` file format is recapped here as follows,
    see: http://www.pomdp.org/code/alpha-file-spec.html

    A set of vectors is the representation use for the value function and each
    vector has an action associated with it. The vectors represent the coefficients
    of a hyperplane passing through the origin. The format specified here is what is
    output from the 'pomdp-solve' program and what will be necessary for input to
    the 'pomdp-solve' program with the '-terminal_values' command line option.

    The format is simply:

    A
    V1 V2 V3 ... VN

    A
    V1 V2 V3 ... VN

    ...


    Where `A` is an action number and the `V1` through `VN` are real values
    representing the components of a particular vector that has the associated
    action. The action number is the 0-based index of the action as specificed in
    the input POMDP file. The vector represents the coefficients of a hyperplane
    representing one facet of the piecewise linear and convex value function.
    Note that the length of the lists needs to be equal to the number of states in
    the POMDP.

    To find which action is the "best" for a given set of alpha vectors, the belief
    state probabilities would be used in a dot product against each alpha vectors'
    coefficients. The action associated with the vector with the highest value is
    the best action to take for that belief state given the value function.
"""
function read_alpha(filename::AbstractString)
    lines = open(readlines, filename)

    alpha_vector_line_indeces = Int[]
    vector_length = -1

    for i in eachindex(lines)

        matches = collect((m.match for m = eachmatch(REGEX_FLOATING_POINT, lines[i])))

        if length(matches) > 1
            push!(alpha_vector_line_indeces, i)
            @assert occursin(r"^(\d)*$", lines[i-1]) "previous line must contain an action index"

            if vector_length == -1
                vector_length = length(matches)
            else
                @assert vector_length == length(matches) "vector length is inconsistent. Was $vector_length, is $(length(matches)) on line $i"
            end
        end
    end
    num_alpha_vectors = length(alpha_vector_line_indeces)

    # Initialize the Γ matrix.
    # The α-vectors are the columns
    alpha_vectors = Array{Float64}(undef, vector_length, num_alpha_vectors)

    # Initialize the alpha_actions vector
    # alpha_actions[i] is the index of the action associated with
    # the alpha-vector in the ith column of alpha_vectors
    # Note that these are 0-indexed
    alpha_actions = Array{Int}(undef, num_alpha_vectors)

    for (i,line_index) in enumerate(alpha_vector_line_indeces)
        alpha_actions[i] = parse(Int, lines[line_index-1])

        for (j,match) in enumerate(eachmatch(REGEX_FLOATING_POINT, lines[line_index]))
            alpha_vectors[j,i] = parse(Float64, match.match)
        end
    end

    return alpha_vectors, alpha_actions
end
"""
    Read a .pomdp file following the specfication at http://www.pomdp.org/code/pomdp-file-spec.html and returns a FilePOMDP or SFilePOMDP object that can be used within the POMDPs.jl interface.
"""
function read_pomdp(filename::String; output::Symbol = :SWildcardArrayPOMDP)
    lines = open(readlines, filename) |> remove_comments_and_white_space 

    # Getting info from preamble
    regex_filtering_preamble = r"\s*[RTO]\s*:"
    preamble = lines[1:findfirst(startswith.(lines, regex_filtering_preamble))-1]
    preamble_dict = check_preamble_fields(join(preamble, "\n"))
    discount, type_reward, actions, states, observations = process_preamble(preamble_dict)
    
    dic_states = Dict(string(nn) => index for (index, nn) in enumerate(names(states))) # needed here to process the initial state

    # # # # Processing the initial distribution
    init_state_tuple = Dict((kk,vv) for (kk, vv) in preamble_dict if kk in ["start", "start include", "start exclude"])
    sorted_keys = sort(collect(init_state_tuple), by=x->x[2].priority)
    initialstate = InitialStateParam()

    for (kk,vv) in sorted_keys 
        initialstate_content = vv.value
        types = [Float64, Int]
        tmp_initialstate_content = map(x->tryparse.(x, string.(split(initialstate_content))), types)

        if isequal(kk, "start")
            if isequal(initialstate_content, "uniform")
                initialstate.support_of_distribution = Set([i for i in Base.OneTo(number(states))])
                initialstate.value_of_distribution = (1/number(states))*ones(number(states))
                initialstate.type_of_distribution = "uniform"
                initialstate.number = number(states)

            else
                # Either a vector suming to one
                initialstate.number = number(states)    
                if all(x -> !isnothing(x), tmp_initialstate_content[1]) # or a vector of floats 
                    @assert test_if_probability(tmp_initialstate_content[1]) 

                    # Saving content on InitialStateParam
                    initialstate.value_of_distribution = tmp_initialstate_content[1]
                    initialstate.support_of_distribution = Set(findall(x -> x > 0, initialstate.value_of_distribution))
                    initialstate.type_of_distribution = "general distribution"

                elseif all(x -> !isnothing(x), tmp_initialstate_content[2]) # or a vector of integers 
                    @assert (all(x -> x >= 1 && x <= number(states), tmp_initialstate_content[2])) 

                    # Saving content on InitialStateParam
                    initialstate.support_of_distribution = Set(tmp_initialstate_content[2])
                    initialstate.value_of_distribution = vec((1/length(initialstate.support_of_distribution))*sum(Diagonal(ones(Float64, number(states)))[:, collect(initialstate.support_of_distribution)], dims=2))
                    initialstate.type_of_distribution = "uniform"

                elseif all(x-> x in names(states), string.(split(initialstate_content))) # or a vector of names
                    # Saving content on InitialStateParam
                    init_state = map(x -> dic_states[x], string.(split(initialstate_content)))
                    initialstate.support_of_distribution = Set(init_state)
                    initialstate.value_of_distribution = vec((1/length(initialstate.support_of_distribution))*sum(Diagonal(ones(Float64, number(states)))[:, collect(initialstate.support_of_distribution)], dims=2))
                    initialstate.type_of_distribution = "uniform"

                else
                    error("Unable to parse the initial condition.")
                end
            end
        elseif isequal(kk, "start include")
            if all(x -> !isnothing(x), tmp_initialstate_content[2]) # or a vector of integers 
                initialstate.support_of_distribution = union(initialstate.support_of_distribution, Set(tmp_initialstate_content[2])) # union the sets
            elseif all(x-> x in names(states), string.(split(initialstate_content))) # or a vector of names
                init_state = map(x -> dic_states[x], string.(split(initialstate_content)))
                initialstate.support_of_distribution = union(initialstate.support_of_distribution, Set(init_state))
            end

            initialstate.value_of_distribution = vec((1/length(initialstate.support_of_distribution))*sum(Diagonal(ones(Float64, number(states)))[:, collect(initialstate.support_of_distribution)], dims=2))
            initialstate.type_of_distribution = "uniform"
            initialstate.number = number(states)

        elseif isequal(kk, "start exclude")
            if all(x -> !isnothing(x), tmp_initialstate_content[2]) # or a vector of integers 
                initialstate.support_of_distribution = setdiff(initialstate.support_of_distribution, Set(tmp_initialstate_content[2]))
            elseif all(x-> x in names(states), string.(split(initialstate_content))) # or a vector of names
                init_state = map(x -> dic_states[x], string.(split(initialstate_content)))
                initialstate.support_of_distribution = setdiff(initialstate.support_of_distribution, Set(init_state))
            end

            if !isempty(initialstate.support_of_distribution)
                initialstate.value_of_distribution = vec((1/length(initialstate.support_of_distribution))*sum(Diagonal(ones(Float64, number(states)))[:, collect(initialstate.support_of_distribution)], dims=2))
            end
            initialstate.type_of_distribution = "uniform"
            initialstate.number = number(states)
        else
            error("Unable to parse the initial condition.")
        end
    end

    sorted_fields = order_of_transition_reward_observation(lines, 1)

    files_transition = []
    files_obs = []
    files_values = []
    # Finding the chunk of the file with the transition, observation, and reward specifications
    for (index, (type_of_matrix, line_number)) in enumerate(sorted_fields)
        if index  < length(sorted_fields)
            range_spec = line_number:(sorted_fields[index+1][2] -1)
            if isequal(type_of_matrix, "T")
                files_transition = lines[range_spec]
            end
            if isequal(type_of_matrix, "O")
                files_obs = lines[range_spec]
            end
            if isequal(type_of_matrix, "R")
                files_values = lines[range_spec]
            end
        else
            range_spec = (line_number:length(lines))
            if isequal(type_of_matrix, "T")
                files_transition = lines[range_spec]
            end
            if isequal(type_of_matrix, "O")
                files_obs = lines[range_spec]
            end
            if isequal(type_of_matrix, "R")
                files_values = lines[range_spec]
            end
        end
    end

    # Processing observation probability
    str_trans = join(files_transition, "\n")
    vv = [names(actions), names(states), names(states)]
    wc_trans = WildcardArray(str_trans, vv)

    # # Processing observation probability
    str_obs = join(files_obs, "\n")
    vv = [names(actions), names(states), names(observations)]
    wc_obs = WildcardArray(str_obs, vv)
    
    # # Processing observation probability
    str_values = join(files_values, "\n")
    vv = [names(actions), names(states), names(states), names(observations)]
    wc_values = WildcardArray(str_values, vv)
    
    pomdp_struc = WildcardArrayPOMDP(number(states), number(actions), number(observations), initialstate, discount[1], wc_trans, wc_obs, wc_values)

    if output == :WildcardArrayPOMDP
        return pomdp_struc

    elseif output == :SWildcardArrayPOMDP
        dic_action = Dict(string(nn) => index for (index, nn) in enumerate(names(actions)))
        dic_obs = Dict(string(nn) => index for (index, nn) in enumerate(names(observations)))

        return SWildcardArrayPOMDP(dic_states, dic_action, dic_obs, pomdp_struc)
    else
        error("Output type invalid")
    end
end
  
################ Auxiliary functions ##################
"""
    test_if_probability(prob::Union{Vector{Float64}, Vector{Nothing}, Nothing};rtol=1e-3)

    Built-in function that tests whether a vector is a probability distribution. It checks if the elements are between 0 and 1 and if the sum of the elements is approximately 1. The function returns true if the vector is a probability distribution and false otherwise.
"""
function test_if_probability(prob::Union{Vector{Float64}, Vector{Nothing}, Nothing};rtol=1e-3)
    if isnothing(prob) || eltype(prob) == Nothing
        return false
    else
        between_0_1 = all(x -> 0 <= x <= 1, prob)
        return (between_0_1 && isapprox(sum(prob), 1; rtol=rtol)) ? true : false
    end
end
"""
    remove_comments_and_white_space(file::Vector{String}) is used by read_pomdp to remove comments and white spaces from the file. This function allows for some standardization of process of parsing files.
"""
function remove_comments_and_white_space(file::Vector{String})
    processed_file = []

    for line in file
        without_comments = replace(line, r"#.*" => "") |> strip

        if !isempty(without_comments)
            push!(processed_file, without_comments)
        end
    end

    return Vector{String}(filter(x -> !isempty(x), processed_file))
end
"""
    convert_to_data_structure(field::String, preamble::Dict{String,String}) is used by read_pomdp to convert the information in the preamble into an intermidiate format before passing it into a ContainerNames object.
"""
function convert_to_data_structure(field::String, preamble::Dict{String,Any}) 
    entry = preamble[field]
    entry = replace(entry, r"\"+" => "")

    return !isnothing(tryparse(Int64, entry)) ? parse(Int64, entry) : string.(split(entry))
end
"""
    order_of_transition_reward_observation(file_lines::Vector{String}, start_line::Int64) is used by read_pomdp to find the order of the transition, reward, and observation matrices in the file.
"""
function order_of_transition_reward_observation(file_lines::Vector{String}, start_line::Int64) 
    key_field = ["O", "T", "R"]
    regex_fields = Vector{String}()

    [push!(regex_fields, "\\s*$field\\s*:") for field in key_field]

    indices = map(x-> findfirst(startswith.(file_lines, Regex(x))), regex_fields)

    dict_scanning = Dict(field => indices[ii] for (ii, field) in enumerate(key_field)) 
    sorted_fields = sort(collect(pairs(dict_scanning)), by=x->x[2])

    return sorted_fields
end

######### Auxiliary functions -- PREAMBLE ###############
"""
    check_preamble_fields(preamble::String) is used by read_pomdp to check if the preamble of the file has all the necessary fields. An error is issued if one of the fields "discount", "values", "states", "actions", or "observations" is missing.
"""
function check_preamble_fields(preamble::String)
    key_fields = ["discount", "values", "states", "actions", "observations"]
    preamble_vec = string.(split(preamble, "\n"))

    preamble_dict = Dict{String, Any}() 
    field_dict = Dict{String, Int64}()

    # Checking whether the preamble has all the necessary fields
    for field in key_fields
        reg_expr = Regex("\\s*$(field)\\s*:")
        index = findfirst(startswith.(preamble_vec, reg_expr))

        if !isnothing(index) 
            field_dict[field] = index
        else
            error("Missing field $(field) in the file")
        end
    end

    regex_preamble = r"\s*(.*)\s*:\s+([\d\D]*?)(?=(.*:)|$)"
    
    for (ii,m) in enumerate(eachmatch(regex_preamble, preamble))
        field = strip(m.captures[1], ['\n', '\r', ' ', '\"'])
        content = strip(m.captures[end-1], ['\n', '\r', ' ', '\"'])

        if field in ["start", "start include", "start exclude"]
            preamble_dict[field] = WildcardArrays.PriorityValue(ii, string(content))
        else
            preamble_dict[field] = content
        end
    end

    return preamble_dict
end
"""
    process_preamble(preamble::Dict{String, String}) is used by read_pomdp to process the preamble of the file and check if the fields "discount", "values", "states", "actions", and "observations" have the correct syntax. The output are the discount, values, actions, states, and observations parameters, where actions, states, and observations are converted into ContainerNames objects.
"""
function process_preamble(preamble::Dict{String, Any})
    # checking discount syntax => it must be a float number
    discount = parse(Float64, preamble["discount"])
    if ~(0 <= discount <= 1) 
        error("Discount parameter must be a number between zero and one") 
    end

    # checking value syntax => either "reward" or "cost"
    values_type = preamble["values"]
    values_param = [(isequal(values_type,"reward")) || (isequal(values_type,"cost") || isequal(values_type, "rewards") || isequal(values_type, "costs")) ? values_type : error("Invalid specification for the objective function.")]
    # checking actions syntax => either an integer or a collection of names
    actions_param = convert_to_data_structure("actions", preamble) 
    # checking states syntax => either an integer or a collection of names
    states_param = convert_to_data_structure("states", preamble) 
    # checking observation syntax => either an integer or a collection of names
    observations_param = convert_to_data_structure("observations", preamble)



    return discount, values_param, ContainerNames(actions_param), ContainerNames(states_param), ContainerNames(observations_param)
end