# POMDP file for the following grid world

#  *
#  **
#   + 

discount: 0.950000
values: reward
states: 13
actions: 3
observations: 9

start:
0.083337 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.0 

# Transition Probabilities
T: 0 : 0 : 0 1.000000
T: 1 : 0 : 1 1.000000
T: 2 : 0 : 3 1.000000
T: 0 : 1 : 1 1.000000
T: 1 : 1 : 2 1.000000
T: 2 : 1 : 0 1.000000
T: 0 : 2 : 6 1.000000
T: 1 : 2 : 3 1.000000
T: 2 : 2 : 1 1.000000
T: 0 : 3 : 3 1.000000
T: 1 : 3 : 0 1.000000
T: 2 : 3 : 2 1.000000
T: 0 : 4 : 0 1.000000
T: 1 : 4 : 5 1.000000
T: 2 : 4 : 7 1.000000
T: 0 : 5 : 9 1.000000
T: 1 : 5 : 6 1.000000
T: 2 : 5 : 4 1.000000
T: 0 : 6 : 0 1.000000
T: 1 : 6 : 7 1.000000
T: 2 : 6 : 5 1.000000
T: 0 : 7 : 7 1.000000
T: 1 : 7 : 4 1.000000
T: 2 : 7 : 6 1.000000
T: 0 : 8 : 8 1.000000
T: 1 : 8 : 9 1.000000
T: 2 : 8 : 11 1.000000
T: 0 : 9 : 9 1.000000
T: 1 : 9 : 10 1.000000
T: 2 : 9 : 8 1.000000
T: 0 : 10 : 12 1.000000
T: 1 : 10 : 11 1.000000
T: 2 : 10 : 9 1.000000
T: 0 : 11 : 7 1.000000
T: 1 : 11 : 8 1.000000
T: 2 : 11 : 10 1.000000
T: * : 12 
0.083337 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.083333 0.0 

# Observation Probabilities
O: * : 0 : 0 1.0
O: * : 1 : 1 1.0
O: * : 2 : 2 1.0
O: * : 3 : 3 1.0
O: * : 4 : 4 1.0
O: * : 5 : 5 1.0
O: * : 6 : 6 1.0
O: * : 7 : 7 1.0
O: * : 8 : 6 1.0
O: * : 9 : 7 1.0
O: * : 10 : 4 1.0
O: * : 11 : 5 1.0
O: * : 12 : 8 1.0

# Rewards
R: * : * : 12 : * 1.000000
